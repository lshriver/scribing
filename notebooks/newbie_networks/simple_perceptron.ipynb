{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation with Sigmoid Activation Function\n",
    "\n",
    "`forward_propagation(input_data, weights, bias)` computes the forward propagation operation of a perceptron and returns the output after applying the `sigmoid(x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"The sigmoid activation function\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def forward_propagation(input_data: np.ndarray, weights: np.ndarray, bias: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Performs the forward propagation step in a neural network layer.\n",
    "\n",
    "    Args:\n",
    "        input_data: The input data or activations from the previous layer. \n",
    "                                    It should be a 1D or 2D array where each row represents a data sample.\n",
    "        weights: The weights associated with the connections between the neurons of the current layer \n",
    "                                 and the previous layer. It should be a 2D array where each column corresponds to a neuron \n",
    "                                 in the current layer.\n",
    "        bias: The bias terms for the neurons in the current layer. It should be a 1D array where each element \n",
    "                              corresponds to a neuron in the current layer.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The output of the current layer after applying the activation function (sigmoid in this case).\n",
    "    \"\"\"\n",
    "    # take the dot product of input and weight and add the bias\n",
    "    return sigmoid(np.dot(input_data, weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward propagation output: 0.9999979547735586\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "X = np.array([2, 3]) # declaring two data points\n",
    "Y = np.array([0]) # label\n",
    "weights = np.array([2.0, 3.0]) # weights of perceptron\n",
    "bias = 0.1 # bias value\n",
    "output = forward_propagation(X, weights.T, bias) # predicted label\n",
    "print(\"Forward propagation output:\", output)\n",
    "\n",
    "Y_predicted = (output > 0.5) * 1 ## apply sigmoid activation\n",
    "print(\"Label:\", Y_predicted)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
